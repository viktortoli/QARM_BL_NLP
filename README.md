# Black-Litterman Portfolio Optimizer with Sentiment Analysis

A web application that constructs optimal stock portfolios by integrating the Black-Litterman model with NLP-based sentiment analysis of financial news.

## Project Overview

This project explores the question: Can news sentiment be systematically incorporated into portfolio optimization?

The application combines the Black-Litterman portfolio optimization framework with Natural Language Processing to automatically generate investor views from financial news articles. Rather than requiring manual input of expected returns, the system uses FinBERT (a financial-domain language model) to analyze news sentiment and translate it into quantitative views.

## Choices & Limits to be adressed

The project idea is to integrate views generated by sentiment analysis to create Black-Litterman optimized portfolios. The idea alone faces a limitation in the fact that news are supposed to be quickly integrated within prices and would not help predict future returns (views), except maybe for some momentum effect. We knew this before-hand but still went for this project because it sounded fun and challenging.

Regarding the data for the NLP, we tried to find ways to get Twitter/Stocktwit data first, but the API's got too restrictive over time and are almost impossible to get for a group of students like us. We explored Reddit as the API is readily available but the lack of structure, the high amount of sarcasm and their tilt on either Mega Caps or Small (Tiny) Caps and other issues coming from such forums posts made us scrap the idea of working with Reddit. We thus looked into Finnhub for live news data.

We thank Mr. Divernois for proposing to help with historical StockTwit data but we really wanted to work with "live" data for its challenging aspect (in terms of pipeline, unpredictability of future news, etc...).

FinnHub has its limitations when it comes to NLP. 
Some of the limitations we adressed:
- A given news headline might (often) flag tickers while not mentioning the company itself (ex: Cryptocurrency news tagging AAPL)
- Multiple companies mentioned, some with positive sentiment, some with negative sentiment (ex: NVDA beats the expectation while AAPL just looks -> whole message is flagged positive for NVDA/AAPL)

We adressed these by stricly limiting, for each post, to only consider the FIRST ticker (most oftentimes is actually the subject), verifying the company is mentioned (check for ticker, company name or even CEOs), and switched to LLM model (Haiku3) to better target the sentiment (we ask for the sentiment of the ticker itself, not the general one) which is impossible with models like FinBERT.


## Background

### The Black-Litterman Model

Traditional mean-variance optimization (Markowitz, 1952) is highly sensitive to expected return estimates. Small errors in inputs can lead to extreme, concentrated portfolios that are impractical for real-world use.

The Black-Litterman model (1992) addresses this by:

1. **Starting from Market Equilibrium** - Rather than estimating expected returns directly, we reverse-engineer the implied returns that justify current market capitalizations. This assumes markets are reasonably efficient.

2. **Incorporating Investor Views** - Views about expected returns (absolute or relative) can be layered on top of equilibrium returns, each with an associated confidence level.

3. **Bayesian Combination** - The model uses Bayesian inference to blend equilibrium returns with investor views. Higher confidence views have more influence on the final expected returns.

The result is more stable, diversified portfolios that reflect both market consensus and investor beliefs.

### Sentiment Analysis with Claude

Instead of manually specifying views, this project automates view generation using sentiment analysis:

1. **News Collection** - Financial news articles are fetched from Finnhub API for S&P 500 stocks
2. **Relevance Filtering** - Articles are filtered to ensure the ticker is the primary subject (CEO names, company aliases, and product names are mapped to tickers)
3. **Sentiment Classification** - Headlines are analyzed using Claude Haiku (claude-3-haiku), which outputs sentiment scores (-1 to +1), confidence levels, and labels. FinBERT is available as an alternative.
4. **Time-Weighted Aggregation** - Recent articles are weighted more heavily using exponential decay
5. **View Generation** - Sentiment scores are converted to Black-Litterman views using the formula:
   ```
   View = Equilibrium Return + kappa * Sentiment * Volatility
   ```

## System Architecture

```
StockTwit/
├── app/
│   ├── main.py                      # Application entry point
│   ├── pages/
│   │   ├── 1_Stock_Selection.py     # Stock universe selection
│   │   ├── 2_Views_Configuration.py # View and parameter settings
│   │   └── 3_Results.py             # Portfolio results and analysis
│   ├── backend/
│   │   ├── bl_model.py              # Black-Litterman implementation
│   │   ├── bl_view_generator.py     # Sentiment to view conversion
│   │   ├── sentiment_analyzer.py    # FinBERT wrapper
│   │   ├── calculations.py          # Portfolio calculations
│   │   └── factor_analyzer.py       # Fama-French factor analysis
│   ├── components/
│   │   ├── charts.py                # Visualization components
│   │   ├── metrics.py               # Performance metrics display
│   │   └── sentiment.py             # Sentiment display components
│   └── database/
│       └── db_manager.py            # PostgreSQL interface
├── scripts/
│   ├── fetch_prices.py              # Price data collection
│   ├── fetch_sentiment.py           # News and sentiment collection
│   └── fetch_factors.py             # Fama-French factor data
└── requirements.txt
```

## Mathematical Framework

### Equilibrium Returns

The implied equilibrium returns are calculated as:

```
pi = delta * Sigma * w_mkt
```

Where:
- pi = equilibrium excess returns
- delta = risk aversion coefficient
- Sigma = covariance matrix
- w_mkt = market capitalization weights

### Posterior Returns

Given a set of views, the posterior expected returns are:

```
mu_BL = inv(inv(tau*Sigma) + P'*inv(Omega)*P) * (inv(tau*Sigma)*pi + P'*inv(Omega)*Q)
```

Where:
- tau = uncertainty scalar on equilibrium returns
- P = pick matrix identifying assets in each view
- Q = vector of view returns
- Omega = diagonal matrix of view uncertainties

### Sentiment to View Conversion

```
View_i = pi_i + kappa * sentiment_i * sigma_i
```

The sentiment adjustment is scaled by volatility to account for the fact that the same sentiment magnitude should have different impacts on high vs. low volatility stocks.

### Sentiment Score Aggregation

Each ticker may have multiple news articles over a given time window. To produce a single sentiment score per ticker, we use a weighted average that accounts for both recency and model confidence:

```
S_weighted = sum(w_t * s_t) / sum(w_t)
```

Where:
- `s_t` = sentiment score of article t (range -1 to +1)
- `w_t` = weight for article t

The weight for each article is calculated as:

```
w_t = c_t * exp(-lambda * (T - t))
```

Where:
- `c_t` = confidence score from the sentiment model (0 to 1)
- `lambda` = decay parameter (default 0.25)
- `T - t` = days elapsed since article publication

This weighting scheme ensures that:
- Recent articles have more influence than older ones (exponential decay)
- High-confidence predictions contribute more than uncertain ones
- A 7-day lookback window is used by default

- We require a minimum of articles before using a score to create a view. As BL is highly sensitive to these inputs, we consider it cautious to aggregate a minimum of articles to not overweight one particular new into a long term view

## Key Parameters

| Parameter | Description | Default |
|-----------|-------------|---------|
| Tau | Uncertainty in equilibrium returns | 0.025 |
| Risk Aversion (delta) | Investor risk tolerance | 2.5 |
| Kappa | Sentiment impact multiplier | 0.1 |
| View Confidence | Confidence in sentiment-derived views | 50% |
| Max Weight | Maximum allocation per stock | 30% |

## Data Sources

- **Price Data**: Yahoo Finance (yfinance library)
- **News Articles**: Finnhub API
- **Sentiment Model**: Claude Haiku (claude-3-haiku) via Anthropic API, with FinBERT as alternative
- **Factor Data**: Kenneth French Data Library
- **Database**: PostgreSQL

## Features

- Selection from S&P 500 universe with 5 years of historical data
- Automated sentiment-based view generation
- Manual view override capability
- Portfolio optimization with weight constraints
- Factor exposure analysis (Fama-French 5 factors)
- Historical performance comparison against benchmark
- Export functionality for portfolio allocations

## Installation

```bash
# Clone the repository
git clone https://github.com/viktortoli/StockTwit.git
cd StockTwit

# Install dependencies
pip install -r requirements.txt

# Set environment variables
set DATABASE_URL=postgresql://...
set FINNHUB_API_KEY=your_api_key

# Run the application
streamlit run app/main.py
```

## Automated Data Collection

The project includes GitHub Actions workflows for automated data updates:
- **fetch-prices.yml** - Daily stock price updates
- **fetch-sentiment.yml** - Daily news collection and sentiment analysis

## Limitations

1. **Sentiment is not predictive** - Positive sentiment does not guarantee positive returns. Markets are largely efficient and may already reflect publicly available information.

2. **Historical covariance assumptions** - The covariance matrix is estimated from historical data and may not reflect future relationships, particularly during market stress.

3. **News timing** - By the time news is published and analyzed, price movements may have already occurred.

4. **Model limitations** - While Claude generally handles financial text well, edge cases like sarcasm or ambiguous phrasing can still be misclassified.

## References

Black, F., & Litterman, R. (1992). Global Portfolio Optimization. Financial Analysts Journal, 48(5), 28-43.

He, G., & Litterman, R. (1999). The Intuition Behind Black-Litterman Model Portfolios. Goldman Sachs Investment Management Research.

Araci, D. (2019). FinBERT: Financial Sentiment Analysis with Pre-trained Language Models. arXiv:1908.10063.

Fama, E. F., & French, K. R. (2015). A Five-Factor Asset Pricing Model. Journal of Financial Economics, 116(1), 1-22.

## Technologies

- Python 3.11
- Streamlit
- PyTorch
- HuggingFace Transformers
- PostgreSQL
- NumPy / Pandas
- Plotly
- SciPy